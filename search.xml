<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Correctness of Horner's Rule]]></title>
    <url>%2F2019%2F07%2F22%2FCorrectness-of-Horner-s-Rule%2F</url>
    <content type="text"><![CDATA[ProblemThe following code fragment implements Horner’s rule for evaluating a polynomial: P(x)=\sum_{k=0}^{n}a_k*x^k\\\quad\quad=a_0+x(a_1+x(a_2+...+x(a_{n-1}+xa_n)))given the coefficients a0,a1,…,an and a value for x. 123y=0for i=n downto 0 y=a[i]+x*y a. In terms of \Theta-notation, what is the running time of this code fragment for Horner’s rule? b. Write pseudocode to implement the naive polynomial-evaluation algorithm that computes each term of the polynomial from scratch. What is the running time of this algorithm? How does it compare to Horner’s rule? c. Consider the following loop invariant:At the start of each iteration of the for loop of lines 2–3, ​ y=\sum_{k=0}^{n-(i+1)} a_{k+i+1}*x^k Interpret a summation with no terms as equaling 0. Following the structure of the loop invariant proof presented in this chapter, use this loop invariant to show that, at termination,y=\sum_{k=0}^{n}a_k*x^k. d. Conclude by arguing that the given code fragment correctly evaluates a polynomial characterized by the coefficients a0,a1,…,an ProofsProof aT_{Horner's}(n)=\Theta(n)Proof bT_{naive}(n)=\Theta(n^2)Proof cif at the end of loop i=m,we have y=x\sum_{k=0}^{n-(i+1)} a_{k+i+1}*x^k+a_ithen,at the end of loop i-1,we have y=x*(x\sum_{k=0}^{n-(i+1)} a_{k+i+1}*x^k+a_i)+a_{i-1}\\\quad=x\sum_{k=0}^{n-(i)} a_{k+i}*x^k+a_{i-1}thus when i=0 y=\sum_{k=0}^{n-1} a_{k+1}*x^k+a_0=\sum_{k=0}^{n}a_{k}*x^kProof d…]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Correctness of Bubblesort]]></title>
    <url>%2F2019%2F07%2F22%2FCorrectness-of-Bubblesort%2F</url>
    <content type="text"><![CDATA[ProblemBubblesort is a popular, but inefficient, sorting algorithm. It works by repeatedly swapping adjacent elements that are out of order. 12345Bubblesort(A) for i=1 to A.length-1 for j=A.length downto i+1 if A[j]&lt;A[j-1] exchange A[j] with A[j-1] a. Let A’ denote the output of BUBBLESORT(A).To prove that BUBBLESORT is correct, we need to prove that it terminates and that A’[1]&lt;=A’[2]&lt;=……&lt;=A’[n] (2.3), ​ where n=A.length.In order to show that BUBBLESORT actually sorts,what else do we need to prove? ​ The next two parts will prove inequally(2.3). b. State precisely a loop invariant for the for loop in lines 2–4, and prove that this loop invariant holds. Your proof should use the structure of the loop invariant proof presented in this chapter. c. Using the termination condition of the loop invariant proved in part (b), state a loop invariant for the for loop in lines 1–4 that will allow you to prove inequality (2.3). Your proof should use the structure of the loop invariant proof presented in this chapter. d. What is the worst-case running time of bubblesort? How does it compare to the running time of insertion sort? ProofsProof bInitialization when j=n,the process will make sure that the smallest of A[n-1] and A[n] will be set in A[n-1]. Maintenance when j=m,the smallest of A[m+1,…,n] will be in A[m+1].if A[m+1]A[m] then A[m] is originally the smallest of A[m,…,n]. In a word,A[m] will be the smallest of A[m,…,n]. Termination the condition causing the loop to terminate is that j == i+1.then we have A[i] to be the smallest of A[i,…,n]. Proof cInitialization when i=1,the process will make sure A[1] is the smallest of A[1,…,n]. Maintenance when i=m,the smallest of A[m,…,n] will be in A[m].if we’ve done the previous process correctly,we will have the first m-1th smallest numbers sorted in A[1,…,m-1].then we have subarray A[1,…,m] sorted. Termination the condition causing the loop to terminate is that i==n-1.then we have A[1,…,n-1] sorted.and if we’ve done the previous process correctly A[n] must be the biggest number of A.so we have the whole array sorted.hence the algorithm is right. Proof aproved in proof c&amp;b Proof dwe meet the worst case when the array is listed in descending order. T_{worst-case}(n)=\sum_{i=1}^{i\leq n}(i-1)=\Theta(n^2)]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chapter 4.Conservation of Energy]]></title>
    <url>%2F2019%2F07%2F08%2FChapter-4-Conservation-of-Energy%2F</url>
    <content type="text"><![CDATA[4-1 What is Energy(blocks indestructible)The conservation of energy​ There is a numerical quantity(energy) that does not change in the manifold changes which nature undergoes. It’s not a description of a mechanism,or anything concrete;it’s just a change fact that we can calculate some number and when we finish watching nature go through her tricks and calculate the number again, it is the same. (Something like the bishop on a red square, and after a number of moves—details unknown—it is still on some red square. It is a law of this nature.) An analogy of “energy”A boy in a enclosed room is playing blocks which are absolutely indestructible. Whenever mom checks the number of bricks,it’s the same. If it’s not the same,maybe he just hid some in a box,gave some to other children,or threw some out of the window. When mom wants to check the number of blocks in the box which can’t be opened,she can weigh the box and calculate the number of blocks inside. ​ (number of blocks seen)+((weight of box)−16 ounces)/3 ounces=constant. There then appear to be some new deviations, but careful study indicates that the dirty water in the bathtub is changing its level. The child is throwing blocks into the water, and she cannot see them because it is so dirty, but she can find out how many blocks are in the water by adding another term to her formula. ​ (number ofblocks seen)+((weight of box)−16)/ounces3 ounces=constant. Properties When calculate the energy,some may leave the system and some may come in.In order to verify the conservation of energy,be careful that we haven’t put any in or taken any out. Energy has lots of forms,and there is a formula for each one(box,dirty water) 4-2 Gravitational Potential Energy]]></content>
      <tags>
        <tag>feynman physics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chapter 2.Basic Physics]]></title>
    <url>%2F2019%2F07%2F08%2FChapter-2-Basic-Physics%2F</url>
    <content type="text"><![CDATA[2-1 Introduction3 Ways to Check Our “guess” There may be simple situations of so few parts that we can predict exactly what will happen,thus check how our rules work. Check rules in terms of less specific rules derived from them. Rought approxiamation. 2-2 Physics before 1920electronmagnetic field. The Electromagnetic Spectrum Frequency in oscillations/sec Name Rough behavior 102 Electrical disturbance Field 5*105~106 Radio broadcast Waves 108 FM-TV Waves 1010 Radar Waves (infrared)5*1014~1015(ultraviolet) Light Waves 1018 X-rays Particle 1021 gamma rays nuclear Particle 1024 gamma rays artificial Particle 1027 gamma rays in cosmic rays Particle 2-3 Quantum physics(after 1920)The Uncertainty Principle\Delta x\Delta p\geq \frac{h}{4\pi}This explains why a crystal is cooled to absolute zero but the atoms are still moving.Because if they stopped moving,we know where they are and they have zero motion,and that is against the uncertainty principle. 2-4 Nuclei and Particles]]></content>
      <tags>
        <tag>feynman physics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chapter 1.Atoms in Motion]]></title>
    <url>%2F2019%2F07%2F07%2FChapter-1-Atoms-in-Motion%2F</url>
    <content type="text"><![CDATA[Here’s notes and abstract of Feynman Physics . 1-1 Introduction1.A Tremendous SubjectPhysics: two hundred years of the most rapidly developing field of knowledge that there is. But it is possible to condense the enormous mass of results to a large extent——to find laws which summarize all our knowledge. Explore physics with some kind of map or outline of the relationship of one part of the subject science to another. 2.PropertiesWe don’t know all the basic laws. Everything we know is some kind of approximation. 3.Principle of science​ The test of all knowledge is experiment. Experiment gives hints to help produce the laws. Physicists use imagination to create from these hints,the great generalizations——to guess at the patterns beneath them Then do experiment to check again whether we have made the right guess. 4.Correctness of ExperimentHow can an experiment be “wrong”? Mainly by being inaccurate. eg. The mass of an object seems to change.This is wrong.Mass if found to increase with velocity,but appreciable increases require the velocity near that of light.A true law is:if an object moves with a speed of less than 100 miles/second the mass is constant to within one part in a million. 1(mile)=1609(meters)\\m=\frac{m_o}{\sqrt{1-\frac{v^2}{c^2}}}1-2 Matter is Made of Atoms1.Atomic hypothesis​ All things are made of atoms Atoms are little particles that move around in perpetual motion, attracting each other when they are a little distance apart, but repelling upon being squeezed into one another. eg.Water(or everything that is continuous at a macroscopic level) ​ Look in a drop of water… Smooth water —-&gt;magnify 2000 times(big as a room) Paramecia moving back and forth in smooth water(Biology) —-&gt;magnify 2000 times(15 miles across) Teeming,no longer smooth —-&gt;magnify 250 times(water magnified a billion times) Something similar to the picture above. Idealized model and the fact The particles don’t have sharp edges Schematically in two dimensions,but they move in three dimensions Real particles are continually jiggling and bouncing,turning and twisting around one another.Imagine this as a dynamic picture. ==The atoms are 1 or 2*10^-8 cm in radius.Now 10^-8 cm is called an angstrom: $\AA$== 2.Molecular AttractionThe pull between the molecules. It prevents the water from falling apart. 3.HeatThe jiggling motion is what we represent as heat: when we increase the temperature,we increase the motion 4.Steam Vapor(gas)If the heating continues there comes a time: ​ the molecular attraction is not enough to hold them together and they do fly apart and become separated. If we increase temperature without changing the density of the gas, i.e., if we increase the speed of the atoms,then the atoms hit harder because they are moving faster,and in addition they hit more often,so the pressure increases. Pressure of gas Moving particles,bounce against,piston,pushed by a force,all the time. The force is proportional to the area. If increase the area but keep the number of molecules per cubic centimeter the same,number of collisions increases,with the wall in the same proportion as the area was increased. If put twice molecules in,so as to double density,the same speed, i.e., the same temperature.To an approximation,the collisions,doubled.Pressure is proportional to the density. If consider the true nature of the forces between the atoms,pressure slightly decreases because of the attraction. To an good approximation,if the density is low enough,not many atoms,the pressure is proportional to the density.(i.e., ideal gas) Another situation. Suppose that the piston moves inward so that,atoms,compressed into a smaller place. Atoms pick up speed from collisions against piston,”hotter”,all atoms pick up speed.—-&gt;compress a gas slowly,its temperature increases. Conversely,slow expansion decrease temperature. 5.Crystal(ice)Look in water in another direction,decrease the temperature,liquid water become solid( rigid ). Different from liquids,solids,arranged in some kind of an array( crystalline array ). The crystal pattern of ice makes ice shrinks when it melts. 6.PhaseMelting:atoms vibrating “in place”,with greater and greater amplitude,until shake themselves out of place. ==As we decrease the temperature,the vibration decreases until at absolute zero.== ==Helium,even at absolute zero,does not freeze,unless the pressure is made so great as to make the atoms squash together.== Freezed,but still vibrating. 1-3 Atomic ProcessesDynamic equilibriumwater in a vessel Without a cover Molecules get knocked away one by one.It evaporates. With a cover If as many molecules are leaving as are coming back,then it reaches an equilibrium. Heat transfer Molecules that leave have more energy than the average.Therefore the ones that are left have less average motion than before.So the liquid gradually cools if it evaporates. Conversely,the molecules get stuck speed up the incoming molecule in result in generation of heat. ==Solution:The processes are more complicated.Not only does the water go into the air,but also,from time to time,one of the oxygen or nitrogen molecules will come in and “get lost”,and work its way into the water.If we suddenly take the air away,then the air molecules will leave more rapidly.== SaltSalt crystal is made of ions instead of atoms. icon:An atom which either has a few extra electrons or has lost a few electrons.Ions stick together by electrical attraction. Solution and Precipitation:Because of the attractions of the negative oxygen and positive hydrogen for the ions,some of the ions jiggle loose. Dissolving or Crystallizing?(like the case of evaporation) 1-4 Chemical Reactionseg.C burning in O2 O2 come over to the carbon,and each atom pick up a C atom and go flying off in a new combination——CO. C attracts O more than O attracts O or C attracts C.Therefore the oxygen may arrive with little energy but the C and O will snap together and everything near them pick up energy,kinetic energy is thus generated. Getting heat from the combination of C and O,burning;the heat is in the form of the molecular motion. But in certain circumstances,so enormous,it generates light(flames). In addition,CO may attach another O, become CO2.]]></content>
      <tags>
        <tag>feynman physics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Insertion Sort on Small Arrays in Merge Sort]]></title>
    <url>%2F2019%2F07%2F06%2FInsertion-Sort-on-Small-Arrays-in-Merge-Sort%2F</url>
    <content type="text"><![CDATA[ProblemAlthough merge sort runs in O(nlgn) worst-case time and insertion sort runs in (n2) worst-case time, the constant factors in insertion sort can make it faster in practice for small problem sizes on many machines. Thus, it makes sense to coarsen the leaves of the recursion by using insertion sort within merge sort when subproblems become sufficiently small. Consider a modification to merge sort in which n/k sublists of length k are sorted using insertion sort and then merged using the standard merging mechanism, where k is a value to be determined.a. Show that insertion sort can sort the n/k sublists, each of length k, in O(nk) worst-case time.b. Show how to merge the sublists in O(nlg(n/k)) worst-case time.c. Given that the modified algorithm runs in O(nk+nlg(n/k)) worst-case time,what is the largest value of k as a function of n for which the modified algorithm has the same running time as standard merge sort, in terms of O-notation?d. How should we choose k in practice? ProofsProof a.For every sublist in the size of k,the worst case running time is ​ \Theta(k^2) Together we have n/k sublists in total,so the total running time to sort them with insertion sort is ​ \Theta(\frac{n}{k}*k^2)=\Theta(nk) Proof b.When we sort the n/k sublists,we have previous running time ​ \Theta(nk) To recursively merge these sublists into one list,we spend ​ \Theta(nlgn-\frac{n}{k}*klg(k))=\Theta(nlgn-nlgk)=\Theta(nlg(\frac{n}{k})) So we have ​ \Theta(nk+nlg(\frac{n}{k})) in total. Proof c.Proof d.]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
        <tag>divide and conquer</tag>
        <tag>updating</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Binary Search]]></title>
    <url>%2F2019%2F07%2F05%2FBinary-Search%2F</url>
    <content type="text"><![CDATA[AlgorithmFor a sorted sequence,we can check the midpoint of it against the target value and estimate half of the sequence from further consideration,halfing the size of remaining portion of the sequence each time. 1234567891011BINARY-SEARCH(x) l=1 r=A.length while(l!=r) mid=floor((l+r)/2) //Assume that A is in ascending order if A[mid]&gt;=x r=mid else l=mid+1 //if x is one element in A return true return (x==A[l]) Analysisworst caseAssume the target value lies on the bottom or the top of the array. Then the worst case running time is \Theta(lgn)]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
        <tag>binary search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Merge Sort]]></title>
    <url>%2F2019%2F07%2F05%2FMerge-Sort%2F</url>
    <content type="text"><![CDATA[AlgorithmDivide the n-element sequence to be sorted into two subsequences of n/2 elements each. Conquer: Sort the two subsequences recursively using merge sort. Combine the two sorted subsequences to produce the sorted answer.Merge by calling the auxiliary procedure MERGE(A,p,q,r),where A is an array and p,q,and r are indices into the array to describe the subarrays. ​ Returning to our card playing motif,suppose we have two piles of cards and merge them into a single sorted output pile by choosing the smaller of two cards on the top of the two piles,removing it from its pile and placing this card to the output file.Repeat this step until the two piles are empty.It takes time: ​ \Theta(n),where\quad n=r-p+1 ​ But there might be too much trouble to check either pile is empty in each basic step.So we place on the bottom of each pile a sentinel card,which contains a special value that we use to simplify our code: ​ +\infty ​ So that whenever a card with infinite value is exposed it cannot be the smaller one thus it won’t be taken to the output pile.Meanwhile,we use a counter to terminate the procedure when it increase to r-p+1,where all the r-p+1 cards are put into the output pile. 123456789101112131415161718192021222324MERGE(A,p,q,r) n1=q-p+1 n2=r-q let L[1...n1+1] and R[1...n2+1] be new arrays for i=1 to n1 L[i]=A[p+i-1] for i=1 to n2 R[i]=A[q+i] L[n1+1]=INF R[n2+1]=INF i=1 j=1 for k=p to r if L[i]&lt;=R[j] A[k]=L[i] i=i+1 else A[k]=R[j] j=j+1MERGE-SORT(A,p,r) if p&lt;r q=floor((p+r)/2) MERGE-SORT(A,p,q) MERGE-SORT(A,q+1,r) MERGE(A,p,q,r) AnalysisSet up the recurrence for T(n),the worst running time of merge sort on n numbers. Divide:This step just computes the middle of the array,which takes constant time. ​ D(n)=\Theta(1) Conquer:we recursively solve two subproblems,which takes ​ 2T(n/2) Combine:already noted that MERGE procedure on an n-element subarray takes time O(n) ​ C(n)=\Theta(n) T(n)=\begin{cases}c\quad\quad if\quad n=1,\\2T(n/2)+cn\quad\quad if\quad n>1\end{cases}We construct a recursion tree. The total number of levels of the tree is lgn+1 which can be proved by induction. The tree has lgn+1 levels,each costing cn time,for a total cost of ​ cn(log_2(n)+1)=cnlgn+cn. Result ​ \Theta(nlgn)]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
        <tag>divide and conquer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Divide and Conquer]]></title>
    <url>%2F2019%2F07%2F05%2FDivide-and-Conquer%2F</url>
    <content type="text"><![CDATA[SummaryStepsDivide the problem into a number of subproblems that are smaller instances of the same problem. Conquer the subproblems by solving them recursively.If the subproblem sizes are small enough,however,just solve the subproblems in a straightforward manner. Combine the solutions to the subproblems into the solution for the original problem. AnalysisUse recurrence equation to study the properties(running time,math solution,etc.) of an algorithm containing a recursive call to itself. Running TimeLet T(n) be the running time on a problem of size n. If n is small enough,say n&lt;=c for some constant c,the straightforward solution takes constant time,which we write as ​ \Theta(1) Suppose that our division of the problem yields a subproblems,each of which is 1/b the size of the original.(For merge sort,a=b=2). It takes time T(n/b) to solve one subproblem of size n/b.So it takes time aT(n/b) to solve a of them. Take D(n) time to divide the problem into subproblems and C(n) time to combine the solutions of the subproblems into solution of the original problem. We get the recurrence(recurrence equation): ​ T(n)=\begin{cases}\Theta(1)\quad if\quad n\leq c,\\aT(n/b)+D(n)+C(n)\quad otherwise\end{cases} Rucursion Tree]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>divide and conquer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Analysis of Linear Search]]></title>
    <url>%2F2019%2F07%2F05%2FAnalysis-of-Linear-Search%2F</url>
    <content type="text"><![CDATA[AnalysisAverageAssum that the element being searched for is equally likely to be any element in the array. We use mathematical expectation to describe the average checking steps. E(n)=\frac{1}{n}*(1+2+...+n)=\frac{n+1}{2}Average running time ​ \overline{T}(n)=\Theta(n) Worst CaseObviously,if we search for A[n] and our loop start iterating from A[1] then it’s the worst case. Worst running time ​ T_{worst-case}(n)=\Theta(n)]]></content>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Selection Sort]]></title>
    <url>%2F2019%2F07%2F05%2FSelection-Sort%2F</url>
    <content type="text"><![CDATA[ProblemInput:A sequence of n numbers ​ Output:A permutation(reordering) of the input sequence ​ $&lt;a_1^{‘},a_2^{‘},…,a_n^{‘}&gt;$ such that ​ $a_1^{‘}\leq a_2^{‘}\leq …\leq a_n^{‘}$ AlgorithmStore the sequence in array A.First find the smallest element of A and exchange it with A[1].Then find the second smallest element of A,and exchange it with A[2].Continue this manner n-1 times. 123456789for i=1 to A.length-1 pos=i key=A[i] for j=i+1 to A.length if A[j]&lt;key then pos=j key=A[j] A[pos]=A[i] A[i]=key AnalysisLoop InvariantInitialization When i=1,the loop will find the smallest element and exchange it with A[1].Then our new permutation only consists of A‘[1] (the exchanged one).This subarray is sorted. Maintenance When we have the sub array consist of m-1 numbers,we scan the rest n-m+1 ones to find the mth smallest one of A.If we’ve done the previous process correctly,then the newly found mth smallest element is bigger than every element in the m-1 subarray.Thus the new m subarray is still sorted. Termination The condition causing the loop to terminate is that i &gt; A.length-1 = n-1.Then we have the subarray consists of n-1 elements originally in A.If we’ve done the previous process correctly,then the only element left must be the biggest one of A.So the final array A[1…n] is sorted.Hence the algorithm is right. Running Time​ T_{best-case}(n)=\Theta(n) ​ T_{worst-case}(n)=\Theta(n^2)]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Insertion Sort]]></title>
    <url>%2F2019%2F07%2F04%2FInsertion-Sort%2F</url>
    <content type="text"><![CDATA[ProblemInput:A sequence of n numbers ​ Output:A permutation(reordering) of the input sequence ​ $&lt;a_1^{‘},a_2^{‘},…,a_n^{‘}&gt;$ such that ​ $a_1^{‘}\leq a_2^{‘}\leq …\leq a_n^{‘}$ Algorithm Treat the sequence as a hand of poker cards.Use the order of index(natrual numbers) the iterate the list. Construct a list with an array to realize insertion sort. The list elements are sorted and we can traverse on it or add new elements to it. Pay attention to the trick applied on the code. 1234567for j=2 to A.length key=A[j] i=j-1 while i&gt;0 and A[i]&gt;key A[i+1]=A[i] i=i-1 A[i+1]=key Loop InvariantYou can regard loop invariant as an application of mathematical induction in computer science. Since algorithms use iterative approach,it’s vital for us to use induction to prove that this algorithm is right. Three things about a loop invariant: Initialization:The first iteration of the loop is correct Maintenance:If it is true before an iteration of the loop and it remains true before the next iteration,then the proverties maintain in the loop process. Termination:When the loop terminates,the invariant gives us a useful property that helps show that the algorithm is correct. eg.Take insertion sort as an example: Initialization:when j=2,the array only consists of A[1].This subarray is sorted. Maintenance:The loop works by moving A[j-1],A[j-2],A[j-3]… by one position right until it finds the proper position for A[j],at which point it inserts the value of A[j].The subarray A[1..j] then consists of the elements originally in A[1..j],but in sorted order.Increasing j for the next iteration preserves the loop invariant. Termination:The condition causing for loop to terminate is that j&gt;A.length=n.Then we have the subarray A[1..n] consists of the elements originally in A[1..n],but in sorted order.Observing the A[1..n] is the entire array,we conclude that the entire array is sorted!Hence the algorithm is correct. Analysis12345678 cost timesfor j=2 to A.length c1 n key=A[j] c2 n-1 i=j-1 c4 n-1 while i&gt;0 and A[i]&gt;key c5 $$\sum_&#123;j=2&#125;^&#123;n&#125;t_j$$ A[i+1]=A[i] c6 $$\sum_&#123;j=2&#125;^&#123;n&#125;(t_j-1)$$ i=i-1 c7 $$\sum_&#123;j=2&#125;^&#123;n&#125;(t_j-1)$$ A[i+1]=key c8 n-1 running timeT(n),the running time of INSERTION-SORT on an input of n values. ​ $T(n)=c_1n+c_2(n-1)+c_4(n-1)+c_5\sum\limits_{j=2}^{n}t_j+c_6\sum\limits_{j=2}^{n}(t_j-1)+c_7\sum\limits_{j=2}^{n}(t_j-1)+c_8(n-1)$ best caseThe best case occurs if the array is already sorted.For each j=2,3…,n,we then find that A[j]&lt;=key in line 4 when i has its initial value of j-1.Thus tj=1 for j=2,3,…,n and the best-case running time is ​ $T_{best-case}(n)=c_1n+c_2(n-1)+c_4(n-1)+c_5(n-1)+c_8(n-1)\\\quad \quad =(c_1+c_2+c_4+c_5+c_8)n-(c_2+c_4+c_5+c_8)$ We can express this running time as ​ $T_{best-case}(n)=an+b$ for constants a and b that depend on the statement costs cj ;it is thus a linear function of n. worst caseThe worst case occurs if the array is in reverse sorted order. Then we must compare each element A[j] with each element in the entire sorted subarray A[1…j-1],and so tj =j for j=2,3,…,n.Noting that ​ $\sum\limits_{j=2}^{n}j=\frac{n(n+1)}{2}-1\\and\\\sum\limits_{j=2}^{n}(j-1)=\frac{n(n-1)}{2}$ Find that in the worst case,the running time is ​ T_{worst-case}(n)=c_1n+c_2(n-1)+c_4(n-1)+c_5(\frac{n(n+1)}{2}-1)+c_6*\frac{n(n-1)}{2}+c_7*\frac{n(n-1)}{2}+c_8(n-1)\\\quad \quad =\frac{1}{2}(c_5+c_6+c_7)*n^2+(c_1+c_2+c_4+\frac{c_5}{2}-\frac{c_6}{2}-\frac{c_7}{2}+c_8)*n-(c_2+c_4+c_5+c_8) We can express this running time as ​ $T_{worst-case}(n)=an^2+bn+c$ for constants a,b and c that depend on the statement cost cj ;it is thus a quadratic function of n. Order of GrowthIt is the rate of growth,or order of growth of the running time that really interests us. Therefore we consider only the leading term of a formula.And we also ignore the leading term’s constant coefficient. In the case of insertion sort,we write it has a worst-case running time of ​ $\Theta(n^2)$]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Insert Sort List]]></title>
    <url>%2F2019%2F07%2F03%2FInsert-Sort-List%2F</url>
    <content type="text"><![CDATA[ProblemInput:A sequence of n numbers ​ Output:A permutation(reordering) of the input sequence ​ $&lt;a_1^{‘},a_2^{‘},…,a_n^{‘}&gt;$ such that ​ $a_1^{‘}\leq a_2^{‘}\leq …\leq a_n^{‘}$ AlgorithmSimulate the process of insert sort with list. Use 3 arrays to store the list. bb[i] means “bigger brother”,the left node of the current node. lb[i] means “little brother”,the right node of the current node. Everytime we get a new element we insert it into the list by traversing the list to find the first node whose key is bigger than the element and place it on the left. Code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;bits/stdc++.h&gt;using namespace std;int N;struct ChainList &#123; int hd,bb[100100],lb[100100],ke[100100],ind; void ini() &#123; hd = -1; ind = 0; for(int i=0;i&lt;=N+1;++i) &#123; bb[i]=lb[i]= -1; &#125; &#125; void ins(int el) &#123; if(hd==-1) &#123; hd=ind=1; ke[1]=el; return; &#125; ke[++ind]=el; bool sign = false; int iter; for(iter = hd; ; iter = lb[iter]) &#123; if(ke[iter]&gt;=el) &#123; sign = true; lb[bb[iter]]=ind; bb[ind]=bb[iter]; bb[iter]=ind; lb[ind]=iter; if(iter == hd) &#123; hd = ind; &#125; break; &#125; if(lb[iter]==-1) break; &#125; if(!sign) &#123; lb[iter]=ind; bb[ind]=iter; &#125; &#125;&#125;L;int main() &#123; scanf("%d",&amp;N); L.ini(); for(int i = 1; i &lt;= N; ++i) &#123; int el; scanf("%d",&amp;el); L.ins(el); &#125; for(int iter = L.hd; iter != -1; iter = L.lb[iter]) printf("%d ",L.ke[iter]); fclose(stdin); fclose(stdout); return 0;&#125;]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
        <tag>list</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Wie wird man seinen Schatten los?]]></title>
    <url>%2F2019%2F07%2F03%2FSay-Hi%2F</url>
    <content type="text"><![CDATA[Hello! Listen to this. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364Wie wird man seinen Schatten los?你要如何逃离自己的阴影？Wie sagt man seinem Schicksal Nein?你该如何反抗自己的命运？Wie kriecht man aus der eignen Haut?又要如何冲破枷锁？Wie kann man je ein anderer sein?如何得到重生？Wen soll man fragen, wenn man sich selber nicht versteht?如果认不清自己，又能向谁去探寻？Wie kann man frei sein, wenn man seinem eignen Schatten nie entgeht?如果逃离不出自己的阴影，又能如何真正自由？Wenn der Kampf vorüber ist当你停止抗争und dein Weg zu Ende,孤身一人走到最后bist du nur noch, der du bist.你将接近自己的本真Dann zählt nur noch, was unzerstörbar ist.那只有坚不可摧的灵魂才得以永荣Doch solange wir leben,但只要我们还存留于世ist es uns aufgegeben,就算被弃之不顾uns zu fragen, Tag und Nacht:也要日夜追问自己Wie wird man seinen Schatten los?你要如何逃离自己的阴影？Wie sagt man seinem Schicksal Nein?你该如何反抗自己的命运？Wie kriecht man aus der eignen Haut?又要如何冲破枷锁？Wie kann man je ein anderer sein?如何得到重生？Wen soll man fragen, wenn man sich selber nicht versteht?如果认不清自己，又该向谁去探寻？Wie kann man frei sein, wenn man seinem eignen Schatten nie entgeht?如果逃离不出自己的阴影，又能如何真正自由？Wie wird man seinen Schatten los?你要如何逃离自己的阴影？Wie können wir leben,我们该如何生活(Wie lässt man alles hinter sich?)（又如何将一切抛在脑后？）(Wie jagt man sein Gewissen fort?)（该如何背弃自己的良心？）solang wir nur dem Schicksal dienen?假使我们只屈从于命运？(Wie flieht man vor dem eignen ich?)（要如何逃离自己？）(Wie kann man flüchten,)（该如何逃脱？）Wir können nie,我们永远不能(wenn man sich selbst im Wege steht?)(如果你成为了自己的阻碍？）wir können nie我们永远不能nie,永远不能(Vor deinem Schicksal kannst du nicht fliehen!)（你不能在自己的命运面前退缩！）niemals vor unserm eignen Schatten fliehen!永远不要在我们自己的阴影面前退缩！]]></content>
  </entry>
</search>
